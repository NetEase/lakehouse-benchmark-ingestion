#请填写source端数据库的连接信息
#需设置成大小写不敏感
source.type: MySQL
source.database.name: test2w
source.username: rds
source.password: 123456
source.hostname: sloth-commerce-test2.jd.163.org
source.port: 3332

#读取source端数据的可选配置项
source.table.name: warehouse , item , history
#source.scan.startup.mode: initial
#source.parallelism: 4

#写入sink端数据的可选配置项
#sink.parallelism: 4

#选择sink端数据湖format的类型，并指定sink端数据库名称
#同样需要对sink.type做大小写的统一
sink.type: Iceberg
sink.database.name: iceberg_bug_test

#如果你选择了Arctic，请填写以下信息
#arctic.metastore.url: thrift://10.196.98.23:18112/trino_online_env
##Arctic相关的可选配置项
#arctic.optimize.group.name: default

#如果你选择了Iceberg，请填写以下信息
iceberg.uri: thrift://hz11-trino-arctic-0.jd.163.org:9083
iceberg.warehouse: hdfs://hz11-trino-arctic-0.jd.163.org:8020/user/warehouse/ignore_default
#iceberg相关的可选配置项
#iceberg.catalog.type: hive

#如果你选择了Hudi，请填写以下信息
#hudi.catalog.path: hdfs://hz11-trino-arctic-0.jd.163.org:8020/user/warehouse
#hudi.hive_sync.metastore.uris: thrift://hz11-trino-arctic-0.jd.163.org:9083

#hudi相关的可选配置项
#hudi.table.type: MERGE_ON_READ
#hudi.read.tasks: 2
#hudi.write.tasks: 2
#hudi.compaction.tasks: 2
#hudi.compaction.trigger.strategy: num_or_time

#Flink conf
#state.backend: rocksdb
#state.checkpoints.dir: hdfs://hz11-trino-arctic-0.jd.163.org:8020/user/warehouse/cp-dir
#execution.checkpointing.interval: 60s
