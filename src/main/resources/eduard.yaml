# 请填写source端数据库的连接信息
source.username: rds
source.password: 123456
source.hostname: sloth-commerce-test2.jd.163.org
source.port: 3332

# 读取source端数据的可选配置项
source.scan.startup.mode: initial
source.table.name: *
source.parallelism: 4
source.side.output.parallelism: 4

# 写入sink端数据的可选配置项
sink.parallelism: 4

# 选择sink端数据湖format的类型
sink.type: hudi
sink.database: hudi_test_2w

# 如果你选择了Arctic，请填写以下信息
metastore.url: thrift://10.196.98.23:18112/trino_online_env
## Arctic相关的可选配置项
arctic.optimize.group.name: default

# 如果你选择了Iceberg，请填写以下信息
iceberg.catalog.type: hive
iceberg.uri: thrift://hz11-trino-arctic-0.jd.163.org:9083
iceberg.warehouse: hdfs://hz11-trino-arctic-0.jd.163.org:8020/user/warehouse
# iceberg相关的可选配置项

# 如果你选择了Hudi，请填写以下信息
hudi.catalog.path: hdfs://hz11-trino-arctic-0.jd.163.org:8020/user/warehouse
# hudi相关的可选配置项
hudi.table.type: MERGE_ON_READ
hudi.read.tasks: 2
hudi.write.bucket_assign.tasks: 2
hudi.compaction.tasks: 2
hudi.compaction.trigger.strategy: num_or_time

# Flink conf
state.backend: rocksdb
state.checkpoints.dir: hdfs://hz11-trino-arctic-0.jd.163.org:8020/user/warehouse/cp-dir
execution.checkpointing.interval: 60s
